{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d50f631-9768-4794-ac9c-7d79baa79451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algorithm' 'along' 'an' 'and' 'artificial' 'as' 'atoms' 'biochemistry'\n",
      " 'branch' 'by' 'calculation' 'called' 'chemical' 'chemistry' 'composed'\n",
      " 'compounds' 'computer' 'concepts' 'culture' 'defined' 'demonstrated'\n",
      " 'discipline' 'elements' 'energy' 'everyday' 'experimentation' 'explores'\n",
      " 'finite' 'force' 'implementable' 'in' 'instructions' 'intelligence'\n",
      " 'interaction' 'involved' 'involves' 'ions' 'is' 'its' 'life' 'living'\n",
      " 'machine' 'machines' 'mathematics' 'matter' 'molecules' 'motion'\n",
      " 'natural' 'observation' 'of' 'organisms' 'patterns' 'physics' 'processes'\n",
      " 'related' 'relationships' 'science' 'scientific' 'sequence' 'social'\n",
      " 'society' 'sociology' 'sometimes' 'space' 'study' 'such' 'surrounds'\n",
      " 'that' 'the' 'through' 'time' 'to' 'well' 'with' 'within']\n",
      "(7, 75)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "      'In computer science artificial intelligence sometimes called machine intelligence is intelligence demonstrated by machines',\n",
    "\n",
    "      'Experimentation calculation and Observation is called science',\n",
    "\n",
    "      'Physics is a natural science that involves the study of matter and its motion through space and time, along with related concepts such as energy and force',\n",
    "      \n",
    "      'In mathematics and computer science an algorithm is a finite sequence of well-defined computer-implementable instructions',\n",
    "\n",
    "      'Chemistry is the scientific discipline involved with elements and compounds composed of atoms, molecules and ions',\n",
    "\n",
    "      'Biochemistry is the branch of science that explores the chemical processes within and related to living organisms',\n",
    "\n",
    "      'Sociology is the study of society, patterns of social relationships, social interaction, and culture that surrounds everyday life',\n",
    "         ]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "#['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bc0cf38-c9ee-4f95-918c-552082e8287d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>along</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>artificial</th>\n",
       "      <th>as</th>\n",
       "      <th>atoms</th>\n",
       "      <th>biochemistry</th>\n",
       "      <th>branch</th>\n",
       "      <th>by</th>\n",
       "      <th>...</th>\n",
       "      <th>such</th>\n",
       "      <th>surrounds</th>\n",
       "      <th>that</th>\n",
       "      <th>the</th>\n",
       "      <th>through</th>\n",
       "      <th>time</th>\n",
       "      <th>to</th>\n",
       "      <th>well</th>\n",
       "      <th>with</th>\n",
       "      <th>within</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155804</td>\n",
       "      <td>0.135270</td>\n",
       "      <td>0.219588</td>\n",
       "      <td>0.219588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182277</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.272886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272886</td>\n",
       "      <td>0.129625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235369</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280673</td>\n",
       "      <td>0.280673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.345800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248929</td>\n",
       "      <td>0.176623</td>\n",
       "      <td>0.153345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithm     along        an       and  artificial        as     atoms  \\\n",
       "0   0.000000  0.000000  0.000000  0.000000    0.238814  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.226934    0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.219588  0.000000  0.312924    0.000000  0.219588  0.000000   \n",
       "3   0.272886  0.000000  0.272886  0.129625    0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  0.269381    0.000000  0.000000  0.283548   \n",
       "5   0.000000  0.000000  0.000000  0.133325    0.000000  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  0.118246    0.000000  0.000000  0.000000   \n",
       "\n",
       "   biochemistry    branch        by  ...      such  surrounds      that  \\\n",
       "0      0.000000  0.000000  0.238814  ...  0.000000   0.000000  0.000000   \n",
       "1      0.000000  0.000000  0.000000  ...  0.000000   0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.000000  ...  0.219588   0.000000  0.155804   \n",
       "3      0.000000  0.000000  0.000000  ...  0.000000   0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000  ...  0.000000   0.000000  0.000000   \n",
       "5      0.280673  0.280673  0.000000  ...  0.000000   0.000000  0.199146   \n",
       "6      0.000000  0.000000  0.000000  ...  0.000000   0.248929  0.176623   \n",
       "\n",
       "        the   through      time        to      well      with    within  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.135270  0.219588  0.219588  0.000000  0.000000  0.182277  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.272886  0.000000  0.000000  \n",
       "4  0.174671  0.000000  0.000000  0.000000  0.000000  0.235369  0.000000  \n",
       "5  0.345800  0.000000  0.000000  0.280673  0.000000  0.000000  0.280673  \n",
       "6  0.153345  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[7 rows x 75 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector Space representation\n",
    "import pandas as pd\n",
    "vector = X\n",
    "df1 = pd.DataFrame(vector.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c6921d2-cf47-4d7e-a2bb-8acffb64f420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\OM\n",
      "[nltk_data]     PRAKASH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\OM\n",
      "[nltk_data]     PRAKASH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading basic packages\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "691a697c-b652-438d-80a4-ff84d6000560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78b08b03-208c-4fe7-8d93-b62730a9cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function returns a list of tokenized and stemmed words of any text\n",
    "def get_tokenized_list(doc_text):\n",
    "    tokens = nltk.word_tokenize(doc_text)\n",
    "    return tokens\n",
    "\n",
    "# This function will performing stemming on tokenized words\n",
    "def word_stemmer(token_list):\n",
    "  ps = nltk.stem.PorterStemmer()\n",
    "  stemmed = []\n",
    "  for words in token_list:\n",
    "    stemmed.append(ps.stem(words))\n",
    "  return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d34e5e8-4cfb-4996-86d3-136fe56700bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords from tokenized word list\n",
    "def remove_stopwords(doc_text):\n",
    "  cleaned_text = []\n",
    "  for words in doc_text:\n",
    "    if words not in stop_words:\n",
    "      cleaned_text.append(words)\n",
    "  return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aa54b88-5125-425c-a36e-e78b342ae779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD TOKENS:\n",
      "['Experimentation', 'calculation', 'and', 'Observation', 'is', 'called', 'science']\n",
      "\n",
      "AFTER REMOVING STOPWORDS:\n",
      "['Experimentation', 'calculation', 'Observation', 'called', 'science']\n",
      "\n",
      "AFTER PERFORMING THE WORD STEMMING::\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['experiment', 'calcul', 'observ', 'call', 'scienc']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for single document\n",
    "tokens = get_tokenized_list(corpus[1])\n",
    "print(\"WORD TOKENS:\")\n",
    "print(tokens)\n",
    "doc_text = remove_stopwords(tokens)\n",
    "print(\"\\nAFTER REMOVING STOPWORDS:\")\n",
    "print(doc_text)\n",
    "print(\"\\nAFTER PERFORMING THE WORD STEMMING::\")\n",
    "doc_text = word_stemmer(doc_text)\n",
    "doc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ef372c-e1bf-457d-8ef7-341c59cc9269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiment calcul observ call scienc'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ = ' '.join(doc_text)\n",
    "doc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94100ef3-da88-4d04-bc13-05ca17ec4aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in comput scienc artifici intellig sometim call machin intellig intellig demonstr machin',\n",
       " 'experiment calcul observ call scienc',\n",
       " 'physic natur scienc involv studi matter motion space time , along relat concept energi forc',\n",
       " 'in mathemat comput scienc algorithm finit sequenc well-defin computer-implement instruct',\n",
       " 'chemistri scientif disciplin involv element compound compos atom , molecul ion',\n",
       " 'biochemistri branch scienc explor chemic process within relat live organ',\n",
       " 'sociolog studi societi , pattern social relationship , social interact , cultur surround everyday life']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus = []\n",
    "for doc in corpus:\n",
    "  tokens = get_tokenized_list(doc)\n",
    "  doc_text = remove_stopwords(tokens)\n",
    "  doc_text  = word_stemmer(doc_text)\n",
    "  doc_text = ' '.join(doc_text)\n",
    "  cleaned_corpus.append(doc_text)\n",
    "cleaned_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "367a7155-ddc7-4baf-9bd5-40118cf0a334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algorithm' 'along' 'artifici' 'atom' 'biochemistri' 'branch' 'calcul'\n",
      " 'call' 'chemic' 'chemistri' 'compos' 'compound' 'comput' 'computer'\n",
      " 'concept' 'cultur' 'defin' 'demonstr' 'disciplin' 'element' 'energi'\n",
      " 'everyday' 'experiment' 'explor' 'finit' 'forc' 'implement' 'in'\n",
      " 'instruct' 'intellig' 'interact' 'involv' 'ion' 'life' 'live' 'machin'\n",
      " 'mathemat' 'matter' 'molecul' 'motion' 'natur' 'observ' 'organ' 'pattern'\n",
      " 'physic' 'process' 'relat' 'relationship' 'scienc' 'scientif' 'sequenc'\n",
      " 'social' 'societi' 'sociolog' 'sometim' 'space' 'studi' 'surround' 'time'\n",
      " 'well' 'within']\n",
      "(7, 61)\n"
     ]
    }
   ],
   "source": [
    "vectorizerX = TfidfVectorizer()\n",
    "vectorizerX.fit(cleaned_corpus)\n",
    "doc_vector = vectorizerX.transform(cleaned_corpus)\n",
    "print(vectorizerX.get_feature_names_out())\n",
    "\n",
    "print(doc_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec21fabc-3dcb-4399-9a7b-d3b926bab4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>along</th>\n",
       "      <th>artifici</th>\n",
       "      <th>atom</th>\n",
       "      <th>biochemistri</th>\n",
       "      <th>branch</th>\n",
       "      <th>calcul</th>\n",
       "      <th>call</th>\n",
       "      <th>chemic</th>\n",
       "      <th>chemistri</th>\n",
       "      <th>...</th>\n",
       "      <th>social</th>\n",
       "      <th>societi</th>\n",
       "      <th>sociolog</th>\n",
       "      <th>sometim</th>\n",
       "      <th>space</th>\n",
       "      <th>studi</th>\n",
       "      <th>surround</th>\n",
       "      <th>time</th>\n",
       "      <th>well</th>\n",
       "      <th>within</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.193734</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.233391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.50124</td>\n",
       "      <td>0.416073</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284459</td>\n",
       "      <td>0.236126</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.284459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.306149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306149</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321262</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.321262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540559</td>\n",
       "      <td>0.27028</td>\n",
       "      <td>0.27028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224355</td>\n",
       "      <td>0.27028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithm     along  artifici      atom  biochemistri  branch   calcul  \\\n",
       "0   0.000000  0.000000  0.233391  0.000000        0.0000  0.0000  0.00000   \n",
       "1   0.000000  0.000000  0.000000  0.000000        0.0000  0.0000  0.50124   \n",
       "2   0.000000  0.284459  0.000000  0.000000        0.0000  0.0000  0.00000   \n",
       "3   0.306149  0.000000  0.000000  0.000000        0.0000  0.0000  0.00000   \n",
       "4   0.000000  0.000000  0.000000  0.321262        0.0000  0.0000  0.00000   \n",
       "5   0.000000  0.000000  0.000000  0.000000        0.3337  0.3337  0.00000   \n",
       "6   0.000000  0.000000  0.000000  0.000000        0.0000  0.0000  0.00000   \n",
       "\n",
       "       call  chemic  chemistri  ...    social  societi  sociolog   sometim  \\\n",
       "0  0.193734  0.0000   0.000000  ...  0.000000  0.00000   0.00000  0.233391   \n",
       "1  0.416073  0.0000   0.000000  ...  0.000000  0.00000   0.00000  0.000000   \n",
       "2  0.000000  0.0000   0.000000  ...  0.000000  0.00000   0.00000  0.000000   \n",
       "3  0.000000  0.0000   0.000000  ...  0.000000  0.00000   0.00000  0.000000   \n",
       "4  0.000000  0.0000   0.321262  ...  0.000000  0.00000   0.00000  0.000000   \n",
       "5  0.000000  0.3337   0.000000  ...  0.000000  0.00000   0.00000  0.000000   \n",
       "6  0.000000  0.0000   0.000000  ...  0.540559  0.27028   0.27028  0.000000   \n",
       "\n",
       "      space     studi  surround      time      well  within  \n",
       "0  0.000000  0.000000   0.00000  0.000000  0.000000  0.0000  \n",
       "1  0.000000  0.000000   0.00000  0.000000  0.000000  0.0000  \n",
       "2  0.284459  0.236126   0.00000  0.284459  0.000000  0.0000  \n",
       "3  0.000000  0.000000   0.00000  0.000000  0.306149  0.0000  \n",
       "4  0.000000  0.000000   0.00000  0.000000  0.000000  0.0000  \n",
       "5  0.000000  0.000000   0.00000  0.000000  0.000000  0.3337  \n",
       "6  0.000000  0.224355   0.27028  0.000000  0.000000  0.0000  \n",
       "\n",
       "[7 rows x 61 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(doc_vector.toarray(), columns=vectorizerX.get_feature_names_out())\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "112df29b-526b-4b09-9e76-80173216fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Biochemistry'\n",
    "query = get_tokenized_list(query)\n",
    "query = remove_stopwords(query)\n",
    "q = []\n",
    "for w in word_stemmer(query):\n",
    "  q.append(w)\n",
    "q = ' '.join(q)\n",
    "q\n",
    "query_vector = vectorizerX.transform([q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb894cdc-2c49-4f2b-b875-de7f6f08d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cosine similarities\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosineSimilarities = cosine_similarity(doc_vector,query_vector).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e451ea4-56dd-49e5-b173-9c7fc0bf23e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6 4 3 2 1 0]\n",
      "['biochemistri branch scienc explor chemic process within relat live organ']\n",
      "['sociolog studi societi , pattern social relationship , social interact , cultur surround everyday life']\n",
      "['chemistri scientif disciplin involv element compound compos atom , molecul ion']\n",
      "['in mathemat comput scienc algorithm finit sequenc well-defin computer-implement instruct']\n",
      "['physic natur scienc involv studi matter motion space time , along relat concept energi forc']\n",
      "['experiment calcul observ call scienc']\n",
      "['in comput scienc artifici intellig sometim call machin intellig intellig demonstr machin']\n"
     ]
    }
   ],
   "source": [
    "related_docs_indices = cosineSimilarities.argsort()[:-10:-1]\n",
    "print(related_docs_indices)\n",
    "\n",
    "for i in related_docs_indices:\n",
    "    data = [cleaned_corpus[i]]\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc25a853-f94b-4f85-a43e-128e2ffb76ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
